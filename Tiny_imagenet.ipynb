{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-t-sOL1k1xCR"},"outputs":[],"source":["!pip install pytorch_lightning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H0efEDp517YA"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","\n","import pytorch_lightning as pl\n","import torchvision\n","from torchvision.datasets import MNIST, CIFAR10, ImageNet\n","import os\n","\n","from torchvision.transforms import ToTensor\n","from matplotlib import pyplot as plt\n","\n","from torch.utils.data import DataLoader, random_split, Dataset\n","from torch.optim.lr_scheduler import StepLR\n","\n","from PIL import Image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lO_yb6G61-W_"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, input_channels, output_channels, linear_dim):\n","        super().__init__()\n","        self.linear_dim = linear_dim\n","        self.output_channels = output_channels\n","        self.conv = nn.Conv2d(input_channels, output_channels, kernel_size=3, padding=1)\n","        self.relu = nn.ReLU()\n","        self.pool = nn.MaxPool2d(2,2)    \n","        self.linear = nn.Linear(768, linear_dim)\n","        \n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.relu(x)\n","        x = self.conv(x)\n","        x = self.pool(x)\n","        x = nn.Flatten()(x)\n","        x = self.linear(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iaCGqgYO2A2O"},"outputs":[],"source":["class Decoder(nn.Module):\n","  # TODO: add the linear dimension to the argument\n","    def __init__(self, input_channels, output_channels, linear_dim):\n","        super().__init__()\n","        self.linear = nn.Linear(linear_dim, linear_dim)\n","        #self.unpool = nn.MaxUnpool2d(2)\n","        self.relu = nn.ReLU()\n","        self.deconv = nn.ConvTranspose2d(output_channels, input_channels, kernel_size=3, padding=1)\n","   \n","    def forward(self, z):\n","        # TODO: reshape z before using cnn, knowing that the output of the encoder now is a vector after the linear operator\n","        x = self.linear(z)\n","        x = x.view(x.size(0), 3, 32, 32)\n","        x = self.deconv(x)\n","        x = self.relu(x)\n","        x = self.deconv(x)\n","        x = self.relu(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPEvRnfV2Db-"},"outputs":[],"source":["\n","# Create a PyTorch Lightning class\n","class AutoEncoder(pl.LightningModule):\n","    def __init__(self, input_channels, output_channels, linear_dim):\n","        super().__init__()\n","        self.input_shape = input_channels\n","        self.num_hidden = output_channels\n","        self.latent_dim = linear_dim\n","        self.encoder = Encoder(input_channels, output_channels, linear_dim)\n","        self.decoder = Decoder(input_channels, output_channels, linear_dim)\n","\n","    def forward(self, x):\n","        # Forward pass\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n","    \n","    def configure_optimizers(self):\n","        # TODO: add StepLR learning rate scheduler\n","        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n","        schedduler = StepLR(optimizer, step_size=30, gamma=0.1)\n","        return [optimizer], [schedduler]\n","\n","    def add_noise(self, x):\n","        noise = torch.randn_like(x)\n","        x_noisy = x + noise\n","        return x_noisy\n","\n","    def training_step(self, batch, batch_idx):\n","        # Training step\n","        x = batch\n","        x_noisy = self.add_noise(x)\n","        z = self.encoder(x_noisy)\n","        x_hat = self.decoder(z)\n","        loss = nn.functional.mse_loss(x_hat, x)\n","        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n","        return loss\n","    \n","    def validation_step(self, batch, batch_idx):\n","        # Validation step\n","        x = batch\n","        x_noisy = self.add_noise(x) \n","        z = self.encoder(x_noisy)\n","        x_hat = self.decoder(z)\n","        loss = nn.functional.mse_loss(x_hat, x)\n","        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n","        return loss\n","    \n","    def test_step(self, batch, batch_idx):\n","        # Testing step\n","        x = batch\n","        x_noisy = self.add_noise(x)\n","        z = self.encoder(x_noisy)\n","        x_hat = self.decoder(z)\n","        loss = nn.functional.mse_loss(x_hat, x)\n","        self.log(\"test_loss\", loss, prog_bar=True, logger=True) \n","        # Plot the first 8 images in the batch\n","        if batch_idx == 0:\n","            self.original = x[:8]\n","            self.images_noisy = x_noisy[:8]\n","            self.reconstructions = x_hat[:8]       \n","        return loss\n","    \n","    # final step after training to print original images and the results in the latent space \n","    def on_test_end(self):\n","        for i, (im, recon, origin) in enumerate(zip(self.images_noisy, self.reconstructions, self.original)):\n","            im = im.permute(1, 2, 0)  \n","            recon = recon.permute(1, 2, 0)\n","            origin = origin.permute(1, 2, 0)\n","            #w = self.latent_dim // 8\n","            #z = z.reshape(8, w)\n","\n","            plt.subplot(8, 3, i * 3 + 1)\n","            if i == 0:\n","                plt.title(\"Original Image\")\n","            plt.imshow(origin.detach().cpu().numpy())  \n","            plt.axis(\"off\")\n","\n","            plt.subplot(8, 3, i * 3 + 2)\n","            if i == 0:\n","                plt.title(\"Image with noise\")\n","            plt.imshow(im.detach().cpu().numpy())  \n","            plt.axis(\"off\")\n","\n","            plt.subplot(8, 3, i * 3 + 3)\n","            if i == 0:\n","                plt.title(\"Reconstruction\")\n","            plt.imshow(recon.detach().cpu().numpy()) \n","            plt.axis(\"off\")\n","\n","        plt.show() \n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NqOlD_Ch2Gh4"},"outputs":[],"source":["\n","class TinyImageNetDataModule(pl.LightningDataModule):\n","    def __init__(self, data_dir, batch_size=32):\n","        super().__init__()\n","        self.data_dir = data_dir\n","        self.batch_size = batch_size\n","\n","    def setup(self, stage=None):\n","        self.transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n","         torchvision.transforms.Normalize((0.1307,), (0.3081,)),torchvision.transforms.Resize((32, 32))])\n","\n","        self.train_dataset = TinyImageNetDataset(\n","            data_dir=(self.data_dir+'/train'),\n","            transform=self.transform\n","        )\n","        \n","        self.val_dataset = TinyImageNetDataset(\n","            data_dir=os.path.join(self.data_dir, 'val'),\n","            transform=self.transform\n","        )\n","        self.test_dataset = TinyImageNetDataset(\n","            data_dir=os.path.join(self.data_dir, 'test'),\n","            transform=self.transform\n","        )\n","        \n","        \n","    def train_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            TinyImageNetDataset(data_dir=self.data_dir+'/train', transform=self.transform),\n","            batch_size=self.batch_size,\n","        )\n","\n","    def val_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            TinyImageNetDataset(data_dir=self.data_dir+'/val', transform=self.transform),\n","            batch_size=self.batch_size,\n","        )\n","\n","    def test_dataloader(self):\n","        return torch.utils.data.DataLoader(\n","            TinyImageNetDataset(data_dir=self.data_dir+'/test', transform=self.transform),\n","            batch_size=self.batch_size,\n","        )\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7e973H652I0Y"},"outputs":[],"source":["\n","class TinyImageNetDataset(Dataset):\n","    def __init__(self, data_dir, transform=None):\n","        self.data_dir = data_dir\n","        self.transform = transform\n","        self.image_paths = self.load_data()\n","\n","    def load_data(self):\n","        image_paths = []\n"," \n","        class_folders = os.listdir(self.data_dir)\n","        class_folders.sort()\n","        if(self.data_dir==\"/kaggle/input/tiny-imagenet/tiny-imagenet-200/train\"):\n","            for i, folder in enumerate(class_folders):        \n","                class_path = os.path.join(self.data_dir, folder, 'images')\n","                if(os.path.isdir(class_path)):\n","                    image_names = os.listdir(class_path)\n","\n","                    for image_name in image_names:\n","                        image_path = os.path.join(class_path, image_name)\n","                        image_paths.append(image_path)\n","                \n","        else:\n","            class_path = self.data_dir+\"/images\"\n","            if(os.path.isdir(class_path)):\n","                image_names = os.listdir(class_path)\n","\n","                for image_name in image_names:\n","                    image_path = os.path.join(class_path, image_name)\n","                    image_paths.append(image_path)\n","\n","        return image_paths\n","\n","    \n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, index):\n","        image_path = self.image_paths[index]\n","        if(os.path.isfile(image_path)):\n","            image = Image.open(image_path).convert('RGB')\n","            if self.transform is not None:\n","                image = self.transform(image)\n","            return image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7TPVizTm2Mdm"},"outputs":[],"source":["# Create the model\n","model = AutoEncoder(input_channels=3, output_channels=3 , linear_dim=3072)\n","dataset = TinyImageNetDataModule(data_dir = \"/kaggle/input/tiny-imagenet/tiny-imagenet-200\", batch_size=32)\n","trainer = pl.Trainer(max_epochs=3 , accelerator='gpu', devices=-1)\n","trainer.fit(model, dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZnQnndj32QcV"},"outputs":[],"source":["dataset.setup(stage=\"test\")\n","trainer.test(datamodule=dataset)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN2dzv+3+Q8gQyaznNHFgWH","mount_file_id":"1NkHYf_n-hlTgylsCtPUNtpqAi3AFGpId","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
